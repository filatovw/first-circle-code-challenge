services:
  db:
    image: postgres:17.4
    restart: always
    environment:
      POSTGRES_DB: dwh
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD: apppass
    ports:
      - "5432:5432"
    volumes:
      - ./volumes/db/:/var/lib/postgresql/data
    healthcheck:
      test: pg_isready -U appuser -d dwh
      interval: 10s
      timeout: 1s
      retries: 10

  db-migrate:
    image: liquibase/liquibase:4.32.0
    volumes:
      - ./migrations/changelog.xml:/liquibase/changelog.xml
      - ./migrations/ddl:/liquibase/ddl
      - ./migrations/seeds:/liquibase/seeds
    environment:
      LIQUIBASE_COMMAND_URL: jdbc:postgresql://db:5432/dwh
      LIQUIBASE_COMMAND_USERNAME: appuser
      LIQUIBASE_COMMAND_PASSWORD: apppass
    command: >
      --changeLogFile=changelog.xml
      update
    depends_on:
      db:
        condition: service_healthy
        restart: true

  s3:
    image: minio/minio:RELEASE.2025-03-12T18-04-18Z
    ports:
      - "19000:9000"
      - "19001:9001"
    volumes:
      - ./volumes/s3/:/data
    environment:
      MINIO_ROOT_USER: miniouser
      MINIO_ROOT_PASSWORD: miniopass
    command: "server --console-address 0.0.0.0:9001 --address 0.0.0.0:9000 /minio"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 5s
      timeout: 5s
      retries: 15

  s3-init:
    image: minio/mc:RELEASE.2025-02-21T16-00-46Z
    depends_on:
      s3:
        condition: service_healthy
    entrypoint: > 
      /bin/sh -c "
          sleep 5 
          mc alias set local http://s3:9000 miniouser miniopass && \
          mc mb -p local/reports
        "

  queue:
    image: bitnami/kafka:3.5.1
    container_name: kafka
    hostname: kafka
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
      - ALLOW_PLAINTEXT_LISTENER=yes
    ports:
      - "9092:9092"
      - "9094:9094"
    volumes:
      - ./volumes/queue:/bitnami/kafka
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--bootstrap-server", "kafka:9092", "--list"]
      interval: 10s
      timeout: 5s

  queue-init:
    image: bitnami/kafka:3.5.1
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "
      sleep 5 &&
      kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic transactions --replication-factor 1 --partitions 1 &&
      kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic failedTransactions --replication-factor 1 --partitions 1 &&
      kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic reports --replication-factor 1 --partitions 1
      "
    depends_on:
      queue:
        condition: service_healthy
        restart: true

  tx_stream2db_ingestor:
    build: ./ingestion
    depends_on:
      - queue
      - queue-init
      - db
      - db-migrate
    environment:
      - PG_USER=appuser
      - PG_PASSWORD=apppass
      - PG_HOST=db
      - PG_PORT=5432
      - PG_DATABASE=dwh
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TRANSACTIONS_TOPIC=transactions
      - KAFKA_FAILED_TRANSACTIONS_TOPIC=failedTransactions
      - KAFKA_REPORTS_TOPIC=reports
    command: uv run tx_stream2db_ingestor

  tx_csv2db_ingestor:
    build: ./ingestion
    depends_on:
      - db
      - db-migrate
      - queue
      - queue-init
    environment:
      - PG_USER=appuser
      - PG_PASSWORD=apppass
      - PG_HOST=db
      - PG_PORT=5432
      - PG_DATABASE=dwh
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TRANSACTIONS_TOPIC=transactions
      - KAFKA_FAILED_TRANSACTIONS_TOPIC=failedTransactions
      - KAFKA_REPORTS_TOPIC=reports
    volumes:
      - ./data:/data
    command: uv run tx_csv2db_ingestor --source-path /data/tx_stream_20200101_20240601.csv

  tx_csv2stream_ingestor:
    build: ./ingestion
    depends_on:
      - queue
      - queue-init
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TRANSACTIONS_TOPIC=transactions
      - KAFKA_FAILED_TRANSACTIONS_TOPIC=failedTransactions
      - KAFKA_REPORTS_TOPIC=reports
    volumes:
      - ./data:/data
    command: uv run tx_csv2stream_ingestor --source-path /data/tx_stream_20200101_20240601.csv

  postgresql:
    image: 'bitnami/postgresql:17.5.0'
    environment:
      - POSTGRESQL_DATABASE=bitnami_airflow
      - POSTGRESQL_USERNAME=bn_airflow
      - POSTGRESQL_PASSWORD=bitnami1
    volumes:
      - ./volumes/af_pg:/bitnami/postgresql
    healthcheck:
      test: pg_isready -U bn_airflow -d bitnami_airflow
      interval: 10s
      timeout: 1s
      retries: 10

  airflow:
    image: bitnami/airflow:latest
    environment:
      - AIRFLOW_COMPONENT_TYPE=worker
      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
      - AIRFLOW_EXECUTOR=LocalExecutor
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_LOAD_EXAMPLES=no
    depends_on:
      postgresql:
        condition: service_healthy
        restart: true
    volumes:
      - ./flows/dags:/opt/bitnami/airflow/dags
      - ./flows/init.sh:/opt/init.sh
    command: bash -c 'airflow db migrate && bash /opt/init.sh && airflow standalone'
    ports:
      - '8080:8080'
